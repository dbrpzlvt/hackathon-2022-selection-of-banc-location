{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T15:17:07.109692Z",
     "start_time": "2022-05-25T15:17:06.017931Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "from keplergl import KeplerGl\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "from h3 import h3\n",
    "\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        return pickle.load(handle)\n",
    "        \n",
    "def save_pickle(obj, filepath): \n",
    "    with open(filepath, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T15:17:08.157845Z",
     "start_time": "2022-05-25T15:17:08.155204Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs('configs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T15:17:53.100257Z",
     "start_time": "2022-05-25T15:17:52.243226Z"
    }
   },
   "outputs": [],
   "source": [
    "df_roads = pd.read_csv(\"/Users/dashavecherinka/Downloads/train/roads_dataset.csv\").drop_duplicates()\n",
    "\n",
    "df_transport = pd.read_csv(\"/Users/dashavecherinka/Downloads/train/routes_dataset.csv\").drop_duplicates()\n",
    "\n",
    "df_population = pd.read_csv(\"/Users/dashavecherinka/Downloads/train/rosstat_population_all_cities.csv\").drop_duplicates()\n",
    "df_population = df_population.set_index(df_population['geo_h3_10'].values)\n",
    "\n",
    "df_isochrones = pd.read_csv(\"/Users/dashavecherinka/Downloads/train/isochrones_walk_dataset.csv\").drop_duplicates()\n",
    "df_isochrones = df_isochrones.set_index(df_isochrones['geo_h3_10'].values)\n",
    "\n",
    "df_stops = pd.read_csv(\"/Users/dashavecherinka/Downloads/train/osm_stops.csv\").drop_duplicates()\n",
    "df_stops = df_stops.set_index(df_stops['geo_h3_10'].values)\n",
    "\n",
    "df_companies = pd.read_csv(\"/Users/dashavecherinka/Downloads/train/osm_amenity.csv\").drop_duplicates()\n",
    "df_companies = df_companies.set_index(df_companies['geo_h3_10'].values)\n",
    "\n",
    "df_isochrones2 = pd.read_csv(\"/Users/dashavecherinka/Downloads/train/isochrones_drive_dataset.csv\").drop_duplicates()\n",
    "df_isochrones2 = df_isochrones2.set_index(df_isochrones2['geo_h3_10'].values)\n",
    "\n",
    "df_ATM = pd.read_csv(\"/Users/dashavecherinka/Downloads/train/target_hakaton_spb.csv\", sep = ';').drop_duplicates()\n",
    "df_ATM = df_ATM.set_index(df_ATM['geo_h3_10'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пересчет для роя\n",
    "def location(category,city):\n",
    "        #определяем город\n",
    "    df_ATM_test = df_ATM[df_ATM['gorod'] == 'Санкт-Петербург']\n",
    "    df_isochrones_test = df_isochrones[df_isochrones['city'] == 'Санкт-Петербург']\n",
    "    df_ATM_test = df_ATM_test[df_ATM_test['atm_category'] == category]\n",
    "    df_stops_test = df_stops[df_stops['city'] == 'Санкт-Петербург'] \n",
    "    df_companies_test= df_companies[df_companies['city'] == 'Санкт-Петербург']\n",
    "    df_companies_test2 = df_companies[df_companies['city'] == 'Санкт-Петербург']\n",
    "    df_companies_test2 = df_companies_test2.drop(columns='Банки')  \n",
    "    index = df_ATM_test[df_ATM_test['atm_category'] == category ]['target'].sort_values()[-20:].keys()\n",
    "\n",
    "    #определяем таргет\n",
    "    index = df_ATM_test[df_ATM_test['atm_category'] == category]['target'].sort_values()[-20:].keys()\n",
    "    # Какие хексагоны входят в район\n",
    "    from shapely.geometry import Point\n",
    "    from shapely.geometry.polygon import Polygon\n",
    "    h3_geo={}\n",
    "    for i in index:\n",
    "        if i in df_isochrones_test['geo_h3_10'][:]:\n",
    "            h3_geo[i] = list()\n",
    "            h3_geo[i].append(df_isochrones_test['geo_h3_10'][i])\n",
    "            temp0 = []\n",
    "            for j in range(len(df_isochrones_test['walk_15min'][i][10:][:-2].split(\",\"))):\n",
    "                temp0.append(tuple(float(x) for x in df_isochrones_test['walk_15min'][i][10:][:-2].split(\",\")[j].split())) \n",
    "            polygon = Polygon(temp0)\n",
    "            for j in df_isochrones_test['geo_h3_10'][:]:\n",
    "                point = Point(df_isochrones_test['lon'][j], df_isochrones_test['lat'][j])\n",
    "                if polygon.contains(point) == True:\n",
    "                    h3_geo[i].append(df_isochrones_test['geo_h3_10'][j])\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    # Численность по районам\n",
    "    h3={}\n",
    "    population_list=[]\n",
    "    atm_cnt=[]\n",
    "    stop_list=[]\n",
    "    comp_list=[]\n",
    "    bank_list=[]\n",
    "    for i in h3_geo.keys():\n",
    "        h3[i]=list()\n",
    "        sum_pop = 0\n",
    "        sum_count=0\n",
    "        sum_stop=0\n",
    "        sum_banks=0\n",
    "        for j in list(h3_geo[i]):\n",
    "            if j in df_population['geo_h3_10'][:]:\n",
    "                sum_pop+=df_population['population'][j]\n",
    "            if j in df_ATM_test['geo_h3_10'][:]:\n",
    "                sum_count+=np.nan_to_num(df_ATM_test['atm_cnt'][j])\n",
    "            if j in df_stops_test['geo_h3_10'][:]:\n",
    "                sum_stop+=1\n",
    "            if j in df_companies_test['geo_h3_10'][:]:\n",
    "                sum_banks+=np.nan_to_num(df_companies_test['Банки'][j])\n",
    "\n",
    "        h3[i].append(sum_pop)\n",
    "        h3[i].append(sum_count)\n",
    "        h3[i].append(sum_banks)\n",
    "        h3[i].append(sum_stop)\n",
    "\n",
    "        population_list.append(sum_pop)\n",
    "        atm_cnt.append(sum_count)\n",
    "        stop_list.append(sum_stop)\n",
    "        bank_list.append(sum_banks)\n",
    "\n",
    "    max1=max(population_list)\n",
    "    max2=max(atm_cnt)\n",
    "    max3=max(stop_list)\n",
    "    max4=max(bank_list)\n",
    "\n",
    "\n",
    "    population_list = population_list/max1\n",
    "    atm_cnt = atm_cnt/max2\n",
    "    stop_list = np.array(stop_list)/(max3+0.00000000001)\n",
    "    bank_list = bank_list/(max4+0.00000000001)\n",
    "\n",
    "\n",
    "    import statistics \n",
    "    etalon_pop = np.mean(population_list)\n",
    "    etalon_atm_cnt = statistics.mode(atm_cnt)\n",
    "    etalon_bank_list = np.mean(bank_list)\n",
    "    etalon_stop_list = np.mean(stop_list)\n",
    "    #параметры\n",
    "    particles_amout = 50\n",
    "    iterations_amount = 60\n",
    "    n = 3\n",
    "    mu = 3\n",
    "    lmbd = 2\n",
    "    w1 = 0.1\n",
    "    crossoverProbability = 0.5 \n",
    "    mutationProbability = 0.1\n",
    "    counter=0\n",
    "\n",
    "    #определяем город\n",
    "    df_ATM_test = df_ATM[df_ATM['gorod'] == city]\n",
    "    df_isochrones_test = df_isochrones[df_isochrones['city'] == city]\n",
    "    df_ATM_test = df_ATM_test[df_ATM_test['atm_category'] == category]\n",
    "    df_stops_test = df_stops[df_stops['city'] == city]\n",
    "    df_companies_test=df_companies[df_companies['city'] == city]\n",
    "    #выбор случайных значений роя\n",
    "    import random\n",
    "    particles = random.choices(df_isochrones_test['geo_h3_10'], k = particles_amout)\n",
    "    particles_position = {}\n",
    "    for i in particles :\n",
    "        particles_position[i] = list()\n",
    "        particles_position[i].append(df_isochrones_test['lat'][i])\n",
    "        particles_position[i].append(df_isochrones_test['lon'][i])\n",
    "\n",
    "    #расчет значений целевой функции\n",
    "\n",
    "    best_particles_value_frame = pd.DataFrame.from_dict(particles_position).T\n",
    "    best_particles_value_frame = best_particles_value_frame.rename(columns = {0:'lat',1:'lon',2:'func'})\n",
    "\n",
    "    # Какие хексагоны входят в район\n",
    "    from shapely.geometry import Point\n",
    "    from shapely.geometry.polygon import Polygon\n",
    "    h3_geo={}\n",
    "    for i in particles:\n",
    "        if i in df_isochrones_test['geo_h3_10'][:]:\n",
    "            h3_geo[i] = list()\n",
    "            h3_geo[i].append(df_isochrones_test['geo_h3_10'][i])\n",
    "            temp0 = []\n",
    "            for j in range(len(df_isochrones_test['walk_15min'][i][10:][:-2].split(\",\"))):\n",
    "                temp0.append(tuple(float(x) for x in df_isochrones_test['walk_15min'][i][10:][:-2].split(\",\")[j].split())) \n",
    "            polygon = Polygon(temp0)\n",
    "            for j in df_isochrones_test['geo_h3_10'][:]:\n",
    "                point = Point(df_isochrones_test['lon'][j], df_isochrones_test['lat'][j])\n",
    "                if polygon.contains(point) == True:\n",
    "                    h3_geo[i].append(df_isochrones_test['geo_h3_10'][j])\n",
    "    # Численность по районам\n",
    "    h3={}\n",
    "    population_list=[]\n",
    "    atm_cnt=[]\n",
    "    stop_list=[]\n",
    "    comp_list=[]\n",
    "    bank_list=[]\n",
    "    for i in h3_geo.keys():\n",
    "        h3[i]=list()\n",
    "        sum_pop = 0\n",
    "        sum_count=0\n",
    "        sum_stop=0\n",
    "        sum_banks=0\n",
    "        for j in list(h3_geo[i]):\n",
    "            if j in df_population['geo_h3_10'][:]:\n",
    "                sum_pop+=df_population['population'][j]\n",
    "            if j in df_ATM_test['geo_h3_10'][:]:\n",
    "                sum_count+=np.nan_to_num(df_ATM_test['atm_cnt'][j])\n",
    "            if j in df_stops_test['geo_h3_10'][:]:\n",
    "                sum_stop+=1\n",
    "            if j in df_companies_test['geo_h3_10'][:]:\n",
    "                sum_banks+=np.nan_to_num(df_companies_test['Банки'][j])\n",
    "\n",
    "        h3[i].append(sum_pop)\n",
    "        h3[i].append(sum_count)\n",
    "        h3[i].append(sum_banks)\n",
    "        h3[i].append(sum_stop)\n",
    "\n",
    "        population_list.append(sum_pop)\n",
    "        atm_cnt.append(sum_count)\n",
    "        stop_list.append(sum_stop)\n",
    "        bank_list.append(sum_banks)\n",
    "\n",
    "    max1=max(population_list)\n",
    "    max2=max(atm_cnt)\n",
    "    max3=max(stop_list)\n",
    "    max4=max(bank_list)\n",
    "\n",
    "\n",
    "    population_list = population_list/max1\n",
    "    atm_cnt = atm_cnt/max2\n",
    "    stop_list = np.array(stop_list)/(max3+0.00000000001)\n",
    "    bank_list = np.array(bank_list)/(max4+0.00000000001)\n",
    "\n",
    "    #Пересчет значения целевых функций\n",
    "    func = 1.6 * abs(population_list - etalon_pop) + 1 * abs(atm_cnt - etalon_atm_cnt) + \\\n",
    "    1.2 * abs(stop_list - etalon_stop_list) + 1.4 * abs(bank_list - etalon_bank_list)\n",
    "    j = 0\n",
    "    for i in particles:\n",
    "        particles_position[i].append(func[j])\n",
    "        j+=1\n",
    "\n",
    "    while counter < iterations_amount:\n",
    "\n",
    "        best_particles_value_frame = pd.DataFrame.from_dict(particles_position).T\n",
    "        best_particles_value_frame = best_particles_value_frame.rename(columns = {0:'lat',1:'lon',2:'func'})\n",
    "        # выбор родителей\n",
    "        parents_list = []\n",
    "        best_rand_parent =[(best_particles_value_frame['func'][i],i)\\\n",
    "         for i in random.choices(best_particles_value_frame['func'].keys(), k = 2*(mu-1))]\n",
    "        best_rand_parent.sort(key=lambda x: x[0])\n",
    "        best_rand_parent1 = best_rand_parent[0][1]\n",
    "        best_rand_parent2 = best_rand_parent[1][1]\n",
    "        best_rand_parent3 = best_particles_value_frame['func'].sort_values().keys()[0]\n",
    "        parents_list.append(best_rand_parent1)\n",
    "        parents_list.append(best_rand_parent2)\n",
    "        parents_list.append(best_rand_parent3)\n",
    "\n",
    "        crossover_operator = [[0,0],[0,0]]\n",
    "\n",
    "        while crossover_operator[0] == crossover_operator[1]:\n",
    "            # кроссовер\n",
    "            crossover_operator = []\n",
    "            for i in range(lmbd):\n",
    "                crossover_operator0 = []\n",
    "                crossoverNumber = random.random()\n",
    "                if crossoverNumber > (1 - crossoverProbability):\n",
    "                    glat = np.mean([best_particles_value_frame['lat'][parents_list[0]],\\\n",
    "                        best_particles_value_frame['lat'][parents_list[1]],\\\n",
    "                        best_particles_value_frame['lat'][parents_list[2]]])\n",
    "                    dlat =  best_particles_value_frame['lat'][parents_list[2]] - glat \n",
    "                    if dlat != 0:\n",
    "                        w2 = abs(dlat)\n",
    "                    else: \n",
    "                        w2 = 0.1\n",
    "                    crossover_operator0.append(best_particles_value_frame['lat'][parents_list[0]] + \\\n",
    "                        w1 * dlat + w2 * ((best_particles_value_frame['lat'][parents_list[1]] - best_particles_value_frame['lat'][parents_list[2]])/2))\n",
    "                    glon = np.mean([best_particles_value_frame['lon'][parents_list[0]],\\\n",
    "                        best_particles_value_frame['lon'][parents_list[1]],\\\n",
    "                        best_particles_value_frame['lon'][parents_list[2]]])\n",
    "                    dlon =  best_particles_value_frame['lon'][parents_list[2]] - glon \n",
    "                    if dlon != 0:\n",
    "                        w2 = abs(dlon)\n",
    "                    else: \n",
    "                        w2 = 0.1\n",
    "                    crossover_operator0.append(best_particles_value_frame['lon'][parents_list[0]] + \\\n",
    "                            w1 * dlat + w2 * ((best_particles_value_frame['lon'][parents_list[1]] - best_particles_value_frame['lon'][parents_list[2]])/2))\n",
    "                else:\n",
    "                    crossover_operator0 = list(random.choice(\n",
    "                        ((best_particles_value_frame['lat'][parents_list[0]], best_particles_value_frame['lon'][parents_list[0]]),\\\n",
    "                         (best_particles_value_frame['lat'][parents_list[1]], best_particles_value_frame['lon'][parents_list[1]]),\\\n",
    "                        (best_particles_value_frame['lat'][parents_list[2]], best_particles_value_frame['lon'][parents_list[2]]))))\n",
    "                crossover_operator.append(crossover_operator0)\n",
    "            # полиномиальная мутация\n",
    "            for i in range(lmbd):\n",
    "                polynomial_mutation_number = random.random()\n",
    "                if polynomial_mutation_number > (1 - mutationProbability):\n",
    "                    nu = random.randrange(1,100)\n",
    "                    r1 = random.random()\n",
    "                    if r1 < 0.5:\n",
    "                        delt = (2*r1)**((1/nu)+1) \n",
    "                    else:\n",
    "                        delt = 1 - (2*(1-r1))**((1/nu)+1)\n",
    "                    crossover_operator[i][0] = crossover_operator[i][0] + (best_particles_value_frame['lat'][parents_list[2]]- best_particles_value_frame['lat'][parents_list[1]])* delt\n",
    "                    crossover_operator[i][1] = crossover_operator[i][1] + (best_particles_value_frame['lon'][parents_list[2]]- best_particles_value_frame['lon'][parents_list[1]])* delt\n",
    "            if crossover_operator[0] == crossover_operator[1]:\n",
    "                crossover_operator[1][0] = crossover_operator[1][0] + random.random()\n",
    "                crossover_operator[1][1] = crossover_operator[1][1] + random.random()\n",
    "                                \n",
    "        import math\n",
    "        def lat_lon(list):\n",
    "            lat1 = list[0]\n",
    "            lon1 = list[1]\n",
    "            list3=[(math.sqrt((df_isochrones_test['lat'][i]-lat1)**2+(df_isochrones_test['lon'][i]-lon1)**2),i)\\\n",
    "                   for i in df_isochrones_test['geo_h3_10'][:] ]\n",
    "            list3.sort(key=lambda x: x[0])\n",
    "            return(list3[0][1],list3[1][1])\n",
    "        offspring_list = []\n",
    "        for i in range(len(crossover_operator)):\n",
    "            lat_lon1 = lat_lon(crossover_operator[i])\n",
    "            offspring_list.append(lat_lon1[0])\n",
    "        if offspring_list[0]==offspring_list[1]:\n",
    "            offspring_list[1]=lat_lon1[1]\n",
    "\n",
    "        parent_for_ex = []\n",
    "        rand_par = random.choices(list(particles_position.keys()), k = 1)[0]\n",
    "        parent_for_ex.append(rand_par)\n",
    "        offspring_list.append(rand_par)\n",
    "        rand_par = random.choices(list(particles_position.keys()), k = 1)[0]\n",
    "        parent_for_ex.append(rand_par)\n",
    "        while parent_for_ex[0]==parent_for_ex[1]:\n",
    "            parent_for_ex[1]=random.choices(list(particles_position.keys()), k = 1)[0]\n",
    "        offspring_list.append(parent_for_ex[1])  \n",
    "\n",
    "        from shapely.geometry import Point\n",
    "        from shapely.geometry.polygon import Polygon\n",
    "        h3_geo={}\n",
    "        for i in offspring_list[:2]:\n",
    "            if i in df_isochrones_test['geo_h3_10'][:]:\n",
    "                h3_geo[i] = list()\n",
    "                h3_geo[i].append(df_isochrones_test['geo_h3_10'][i])\n",
    "                temp0 = []\n",
    "                for j in range(len(df_isochrones_test['walk_15min'][i][10:][:-2].split(\",\"))):\n",
    "                    temp0.append(tuple(float(x) for x in df_isochrones_test['walk_15min'][i][10:][:-2].split(\",\")[j].split())) \n",
    "                polygon = Polygon(temp0)\n",
    "                for j in df_isochrones_test['geo_h3_10'][:]:\n",
    "                    point = Point(df_isochrones_test['lon'][j], df_isochrones_test['lat'][j])\n",
    "                    if polygon.contains(point) == True:\n",
    "                        h3_geo[i].append(df_isochrones_test['geo_h3_10'][j])\n",
    "        # Численность по районам\n",
    "        h3={}\n",
    "        population_list=[]\n",
    "        atm_cnt=[]\n",
    "        stop_list=[]\n",
    "        comp_list=[]\n",
    "        bank_list=[]\n",
    "        for i in h3_geo.keys():\n",
    "            h3[i]=list()\n",
    "            sum_pop = 0\n",
    "            sum_count=0\n",
    "            sum_stop=0\n",
    "            sum_banks=0\n",
    "            for j in list(h3_geo[i]):\n",
    "                if j in df_population['geo_h3_10'][:]:\n",
    "                    sum_pop+=df_population['population'][j]\n",
    "                if j in df_ATM_test['geo_h3_10'][:]:\n",
    "                    sum_count+=df_ATM_test['atm_cnt'][j]\n",
    "                if j in df_stops_test['geo_h3_10'][:]:\n",
    "                    sum_stop+=1\n",
    "                if j in df_companies_test['geo_h3_10'][:]:\n",
    "                    sum_banks+=np.nan_to_num(df_companies_test['Банки'][j])\n",
    "\n",
    "            h3[i].append(sum_pop)\n",
    "            h3[i].append(sum_count)\n",
    "            h3[i].append(sum_banks)\n",
    "            h3[i].append(sum_stop)\n",
    "\n",
    "            population_list.append(sum_pop) \n",
    "            atm_cnt.append(sum_count)\n",
    "            stop_list.append(sum_stop)\n",
    "            bank_list.append(sum_banks) \n",
    "        #Пересчет значения целевых функций\n",
    "        func = abs(population_list - etalon_pop) + abs(atm_cnt - etalon_atm_cnt) + \\\n",
    "        abs(stop_list - etalon_stop_list) + abs(bank_list - etalon_bank_list)\n",
    "        j = 0\n",
    "        offspring_list_data = {}\n",
    "        for i in offspring_list:\n",
    "            offspring_list_data[i] = list()\n",
    "            if j < 2:\n",
    "                offspring_list_data[i].append(df_isochrones_test['lat'][offspring_list[j]])\n",
    "                offspring_list_data[i].append(df_isochrones_test['lon'][offspring_list[j]])\n",
    "                offspring_list_data[i].append(func[j])\n",
    "                j+=1\n",
    "            else:\n",
    "                offspring_list_data[i].append(particles_position[offspring_list[j]][0])\n",
    "                offspring_list_data[i].append(particles_position[offspring_list[j]][1])\n",
    "                offspring_list_data[i].append(particles_position[offspring_list[j]][2])\n",
    "                j+=1\n",
    "        del particles_position[offspring_list[2]]\n",
    "        del particles_position[offspring_list[3]]\n",
    "        b =[(offspring_list_data[i][2],i) for i in offspring_list_data.keys()]\n",
    "        b.sort(key=lambda x: x[0])\n",
    "        for i in range(2):\n",
    "            particles_position[b[i][1]]=offspring_list_data[b[i][1]]\n",
    "        counter+=1\n",
    "    q = [(particles_position[i][0],particles_position[i][1],particles_position[i][2],i) for i in particles_position.keys()]\n",
    "    q.sort(key=lambda x: x[0])\n",
    "    return(q[0][0],q[0][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Координаты банкомата  category1  -  (54.84847843465986, 82.97390668520336)\n",
      "Координаты банкомата  category2  -  (54.8171302314008, 83.09541006946871)\n",
      "Координаты банкомата  category3  -  (54.86157327583376, 82.97621963139348)\n",
      "Координаты банкомата  category4  -  (54.84112661283599, 83.10007774967546)\n"
     ]
    }
   ],
   "source": [
    "category_id=['category1', 'category2','category3','category4']\n",
    "coordinat=[]\n",
    "for i in category_id:\n",
    "    coordinat.append(location(i,'Новосибирск'))\n",
    "for i in range(4):   \n",
    "    print(\"Координаты банкомата \" , category_id[i] , \" - \",coordinat[i])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
